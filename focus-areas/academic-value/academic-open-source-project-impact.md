# Academic Open Source Project Impact

Question: What is the impact of open source projects that an academician or a team of academicians creates as an important part of a university reappointment, tenure, and promotion process? 

## Description
Academics need to show evidence of their scholarly output in tenure and promotion cases. Creating an open source project may be an impactful contribution and this metric helps to show this. This metric is for a new project that was created as part of an academic job and released as open source. This metric is not related to open source contributions made to an existing open source project.

## Objectives
The goal is to support RPT (Reappointment, Tenure, and Promotion) by drawing forward key open source impact measures, such as: 
* Understanding the scope of the community around the created open source project 
* Understanding the growth, maturity, or decline of the open source project 
* Identifying other projects that depend on your project 
* Identifying journal articles that reference your project

## Implementation

Some ideas for how to measure Academic Open Source Project Impact:
* Impact measured through publication in Journal of Open Source Software
* Number of downstream-dependencies of software in consideration 
* Something similar to H-Index (doesn’t currently exist)
* CiteAs API provides standardized citations for open source software
* Number of downloads
* [Number of contributors](https://chaoss.community/metric-contributors/)
* Number of software/library citations
* Number of stars (GitHub)
* Number of published articles that cite the software or project
* Downloads of pre-prints that cite the software or project
* [Regularity of updates](https://chaoss.community/metric-activity-dates-and-times/)
* Lines of Code
* Number of community contributions, not from the research team
* Downstream dependencies

### Tools Providing the Metric
* GrimoireLab
* Augur
* [CiteAS](https://citeas.org/)
* [Journal of Open Source Software (JOSS)](https://joss.theoj.org/)
* [GitHub Citation](https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-citation-files)
* [arXiv.org code](https://blog.arxiv.org/2020/10/08/new-arxivlabs-feature-provides-instant-access-to-code/)
* Center for Open Science OSF (Open Science Framework)
* [ACM Artifact Review and Badging](https://www.acm.org/publications/policies/artifact-review-and-badging-current)

## References 
* [GitHub Citation Guidelines for Software](https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-citation-files)
* [arXiv.org code](https://blog.arxiv.org/2020/10/08/new-arxivlabs-feature-provides-instant-access-to-code/)
* [ResearchStory](https://www.researchstory.com/)
* [ACM Artifact Review and Badging](https://www.acm.org/publications/policies/artifact-review-and-badging-current)
* [Altmetric](https://www.altmetric.com/)
* [Related Metric: Project Popularity](https://chaoss.community/metric-project-popularity/)
* [CiteAs](https://citeas.org/about)
* Zhao, R., & Wei, M. (2017). Impact evaluation of open source software: An Altmetrics perspective. Scientometrics, 110(2), 1017–1033. https://doi.org/10.1007/s11192-016-2204-y
* Moral-Muñoz, J. A., Herrera-Viedma, E., Santisteban-Espejo, A., & Cobo, M. J. (2020). Software tools for conducting bibliometric analysis in science: An up-to-date review. El Profesional de La Información, 29(1). https://doi.org/10.3145/epi.2020.ene.03
* Searles, A., Doran, C., Attia, J., Knight, D., Wiggers, J., Deeming, S., Mattes, J., Webb, B., Hannan, S., Ling, R., Edmunds, K., Reeves, P., & Nilsson, M. (2016). An approach to measuring and encouraging research translation and research impact. Health Research Policy and Systems, 14(1), 60. https://doi.org/10.1186/s12961-016-0131-2

## Contributors
* Stephen Jacobs
* Vinod Ahuja
* Elizabeth Barron
* Matt Germonprez
* Kevin Lumbard
* Georg Link
* Sean P Goggins
* Johan Linaker
